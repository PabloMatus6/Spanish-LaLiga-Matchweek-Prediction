{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np \n",
    "import seaborn as sns \n",
    "from pandas import DataFrame\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.datasets import make_classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For this notebook we resort again to the data set used for plotting, as it will also be used for modelling in this section."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>year</th>\n",
       "      <th>round</th>\n",
       "      <th>division</th>\n",
       "      <th>local_goals</th>\n",
       "      <th>visitor_goals</th>\n",
       "      <th>points_local</th>\n",
       "      <th>wins_local</th>\n",
       "      <th>draws_local</th>\n",
       "      <th>losses_local</th>\n",
       "      <th>gf_local</th>\n",
       "      <th>...</th>\n",
       "      <th>pos_local</th>\n",
       "      <th>points_visitor</th>\n",
       "      <th>wins_visitor</th>\n",
       "      <th>draws_visitor</th>\n",
       "      <th>losses_visitor</th>\n",
       "      <th>gf_visitor</th>\n",
       "      <th>ga_visitor</th>\n",
       "      <th>avg_visitor</th>\n",
       "      <th>pos_visitor</th>\n",
       "      <th>match_winner</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>2016</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>2016</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>13</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>2016</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>2016</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>2016</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    year  round  division  local_goals  visitor_goals  points_local  \\\n",
       "10  2016      2         1            3              1             1   \n",
       "11  2016      2         1            0              0             1   \n",
       "12  2016      2         1            1              0             3   \n",
       "13  2016      2         1            3              0             3   \n",
       "14  2016      2         1            5              0             1   \n",
       "\n",
       "    wins_local  draws_local  losses_local  gf_local  ...  pos_local  \\\n",
       "10         0.0          1.0           0.0         1  ...          7   \n",
       "11         0.0          1.0           0.0         0  ...         10   \n",
       "12         1.0          0.0           0.0         1  ...          4   \n",
       "13         1.0          0.0           0.0         2  ...          2   \n",
       "14         0.0          1.0           0.0         0  ...         12   \n",
       "\n",
       "    points_visitor  wins_visitor  draws_visitor  losses_visitor  gf_visitor  \\\n",
       "10               3           1.0            0.0             0.0           1   \n",
       "11               1           0.0            1.0             0.0           0   \n",
       "12               1           0.0            1.0             0.0           0   \n",
       "13               1           0.0            1.0             0.0           0   \n",
       "14               1           0.0            1.0             0.0           1   \n",
       "\n",
       "    ga_visitor  avg_visitor  pos_visitor  match_winner  \n",
       "10           0          1.0            5             0  \n",
       "11           0          0.0           13             1  \n",
       "12           0          0.0            9             0  \n",
       "13           0          0.0           11             0  \n",
       "14           1          0.0            6             0  \n",
       "\n",
       "[5 rows x 22 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('plotting_data', index_col = [0])\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is important to drop the columns referred to the goals from the match in order to do not give this information to the model, as these columns contain information related to the result of the match, namely the goals scored by each team."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.drop(['local_goals', 'visitor_goals'], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modelling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "We start with models based on this data before performing feature engineering. We will observe which classifiers obtain the best prediction values, and based on them, we will have a base prediction result that we will try to improve.\n",
    "\n",
    "For each model, the classification report and the confusion matrix will be obtained. \n",
    "\n",
    "In the classification report you will be able to see the results of success in function of the metrics, they will be evaluated especially for their results in f1 score, especially the accuracy.\n",
    "\n",
    "In the confusion matrix you will get information about the errors and successes made according to the predicted results. . The column number indicates the prediction of the model and the row number indicates the result. On the main diagonal you will find the home, draw and away successes respectively. Outside the diagonal, for example, the first column is the predictions that the model made of a home win based on what the final result was, i.e. the position corresponding to the first column and the second row is the number of matches that the model predicted as a home win that finally turned out to be a draw. The significance of the remaining elements of the matrix are also explained."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5074946466809421"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features = data.values[:, :-1]\n",
    "target = data.values[:, -1]\n",
    "X, y = features, target\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1, random_state=30)\n",
    "scaler = MinMaxScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "\n",
    "model = LogisticRegression(max_iter = 500)\n",
    "model.fit(X_train_scaled, y_train)\n",
    "\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "y_pred = model.predict(X_test_scaled)\n",
    "\n",
    "np.mean(y_pred == y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[191,   5,  22],\n",
       "       [108,   9,  14],\n",
       "       [ 79,   2,  37]], dtype=int64)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "   Local win       0.51      0.88      0.64       218\n",
      "        Draw       0.56      0.07      0.12       131\n",
      " Visitor win       0.51      0.31      0.39       118\n",
      "\n",
      "    accuracy                           0.51       467\n",
      "   macro avg       0.52      0.42      0.38       467\n",
      "weighted avg       0.52      0.51      0.43       467\n",
      "\n"
     ]
    }
   ],
   "source": [
    "target_names = ['Local win', 'Draw', 'Visitor win']\n",
    "print(classification_report(y_test, y_pred, target_names=target_names))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.3747323340471092"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features = data.values[:, :-1]\n",
    "target = data.values[:, -1]\n",
    "X, y = features, target\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1, random_state=30)\n",
    "scaler = MinMaxScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "\n",
    "model = DecisionTreeClassifier()\n",
    "model.fit(X_train_scaled, y_train)\n",
    "\n",
    "predictions_dt = model.predict(X_test)\n",
    "\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "y_pred = model.predict(X_test_scaled)\n",
    "\n",
    "np.mean(y_pred == y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[86, 77, 55],\n",
       "       [44, 42, 45],\n",
       "       [40, 31, 47]], dtype=int64)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "   Local win       0.48      0.21      0.29       218\n",
      "        Draw       0.25      0.24      0.24       131\n",
      " Visitor win       0.19      0.40      0.25       118\n",
      "\n",
      "    accuracy                           0.26       467\n",
      "   macro avg       0.31      0.28      0.26       467\n",
      "weighted avg       0.34      0.26      0.27       467\n",
      "\n"
     ]
    }
   ],
   "source": [
    "target_names = ['Local win', 'Draw', 'Visitor win']\n",
    "print(classification_report(y_test, predictions_dt, target_names=target_names))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.45610278372591007"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features = data.values[:, :-1]\n",
    "target = data.values[:, -1]\n",
    "X, y = features, target\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1, random_state=30)\n",
    "scaler = MinMaxScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "\n",
    "model = RandomForestClassifier()\n",
    "model.fit(X_train_scaled, y_train)\n",
    "\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "y_pred = model.predict(X_test_scaled)\n",
    "\n",
    "np.mean(y_pred == y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[155,  35,  28],\n",
       "       [ 85,  28,  18],\n",
       "       [ 63,  25,  30]], dtype=int64)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "   Local win       0.51      0.71      0.60       218\n",
      "        Draw       0.32      0.21      0.26       131\n",
      " Visitor win       0.39      0.25      0.31       118\n",
      "\n",
      "    accuracy                           0.46       467\n",
      "   macro avg       0.41      0.39      0.39       467\n",
      "weighted avg       0.43      0.46      0.43       467\n",
      "\n"
     ]
    }
   ],
   "source": [
    "target_names = ['Local win', 'Draw', 'Visitor win']\n",
    "print(classification_report(y_test, y_pred, target_names=target_names))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### KNeighbors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.45610278372591007"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "features = data.values[:, :-1]\n",
    "target = data.values[:, -1]\n",
    "X, y = features, target\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1, random_state=30)\n",
    "scaler = MinMaxScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "\n",
    "model =KNeighborsClassifier()\n",
    "model.fit(X_train_scaled, y_train)\n",
    "\n",
    "predictions = model.predict(X_test)\n",
    "\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "y_pred = model.predict(X_test_scaled)\n",
    "\n",
    "np.mean(y_pred == y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[147,  51,  20],\n",
       "       [ 80,  35,  16],\n",
       "       [ 66,  21,  31]], dtype=int64)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "   Local win       0.50      0.67      0.58       218\n",
      "        Draw       0.33      0.27      0.29       131\n",
      " Visitor win       0.46      0.26      0.34       118\n",
      "\n",
      "    accuracy                           0.46       467\n",
      "   macro avg       0.43      0.40      0.40       467\n",
      "weighted avg       0.44      0.46      0.44       467\n",
      "\n"
     ]
    }
   ],
   "source": [
    "target_names = ['Local win', 'Draw', 'Visitor win']\n",
    "print(classification_report(y_test, y_pred, target_names=target_names))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The best prediction result is obtained by one of the simplest models, Logistic Regression. With this model a 51% success rate is obtained in predicting results. Logistic Regression also obtains the best results predicting the categories of 'Local win' and 'Visitor win', obtaining also a very low accuracy in the prediction of 'Draw' (only 12%). \n",
    "\n",
    "It can be observed that for all the classifiers the most difficult category to predict is 'Draw', the model that obtains the best results for this category is KNeighbors (29%), which is the second classifier with the best overall results (46% prediction accuracy).\n",
    "\n",
    "Most of the correct predictions of these models are concentrated on home wins. It is worth mentioning the case of the Kneighbors classifier, which obtains a better final prediction value than random forest, betting a lower number of times on the local victory. This fact is consolidated when observing the classification reports of both, as mentioned in the previous paragraph, Kneighbors stands out for the successes obtained in matches with a draw or away win as opposed to the rest. \n",
    "\n",
    "The logic of these results may be due to the fact that the dataset is not very large, and therefore does not have a sufficiently large number of examples to learn more complex patterns. That is why the model that gives the best results is the simplest one, such as logistic regression.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
